{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dathack_2019_LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2BafKpSjCYY1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/infinitylogesh/Interpretable-NLP-Talk/blob/master/Dathack_2019_LSTM_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXV-8kN1_tZF",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUd476klM-RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,sys,cPickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH5SGUSRE4CN",
        "colab_type": "code",
        "outputId": "9590e9be-cc85-430a-8877-6e8199f4651d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0NDmhj7j9P",
        "colab_type": "text"
      },
      "source": [
        "## Attention Intuition :\n",
        "\n",
        "Attention :\n",
        "\n",
        "In an attention layer, the weight of each token is computed by an alignment model which scores how well the inputs contribute to the classification or the output (in case of seq-seq). An alignment model is a feedforward neural network, for instance. In general, it can be any other model as well.\n",
        "As a result, the alphas — the weights of hidden states when computing a context vector — show how important a given Token.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY20vBNy8wSJ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/N7D7rT9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoCMm4De8lIC",
        "colab_type": "text"
      },
      "source": [
        "After Attention :\n",
        "\n",
        "![alt text](https://i.imgur.com/IGfgRdZ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g32cBfWiCQvt",
        "colab_type": "text"
      },
      "source": [
        "# Token-level importance visualization with Attention weights\n",
        "\n",
        "\n",
        "We use a one layer feed forward style attention ([Bahdanau et al., 2015 ](https://doi.org/10.1146/annurev.neuro.26.041002.131047)) on top of LSTMs to get the token level importance scores. We use these scores in our visualizations. \n",
        "\n",
        "#### Attention :\n",
        "\n",
        "\\begin{align}\\begin{split} \n",
        "\\mathbf{c}_i &= \\sum\\limits_j a_{ij}\\mathbf{s}_j\\\\ \n",
        "\\mathbf{a}_i &= \\text{softmax}(f_{att}(\\mathbf{s}_j)) \n",
        "\\end{split}\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "### Model Architecture.\n",
        "\n",
        "We train a model as shown below on Yelp sentiment analysis dataset to extract the token level importance score.\n",
        "\n",
        "-\n",
        "\n",
        "\n",
        "> ![BiLSTM-Attnetion](https://i.imgur.com/K1NGVcu.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNTOgMsyiRGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.insert(0, './drive/My Drive/talks/Interpretable_NLP/Attention/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtKk-2euiSXK",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from attention import Attention\n",
        "from custom_metrics import f1\n",
        "from pre_process import clean_text,tokenize\n",
        "from keras import models\n",
        "from keras.preprocessing import image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.externals import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from flask import jsonify\n",
        "import logging\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Input,Reshape\n",
        "from keras.layers import Dense,Dropout,Flatten,Activation,GlobalAveragePooling2D,LSTM,Bidirectional\n",
        "from keras.layers import BatchNormalization, Convolution2D, Input,Dropout\n",
        "from keras.layers import Conv1D,Dense, MaxPooling1D,CuDNNLSTM,CuDNNGRU,SpatialDropout1D,Bidirectional,GlobalAveragePooling1D,LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "from keras.layers import Conv1D, MaxPooling1D,CuDNNLSTM,CuDNNGRU,LSTM,GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "import time,os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXuwnR9FiSj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_with_attention_weights(embedding_matrix):\n",
        "        # https://www.kaggle.com/morenoh149/keras-imagedatagenerator-validation-split\n",
        "    inp = Input(shape=(200,))\n",
        "    emb = Embedding(100001, 300, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    sDropout = SpatialDropout1D(0.1)(emb)\n",
        "    lstm = Bidirectional(LSTM(64,return_sequences=True,recurrent_activation='sigmoid'))(sDropout)\n",
        "    lstm = Bidirectional(LSTM(64,return_sequences=True,recurrent_activation='sigmoid'))(lstm)\n",
        "    attention,attn_w = Attention(200,return_attention_weights=True)(lstm)\n",
        "    dense_1 = Dense(128, activation=\"relu\")(attention)\n",
        "    outp = Dense(3, activation=\"softmax\")(dense_1)\n",
        "    model = Model(inputs=inp, outputs=[outp,attn_w])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVWJNi0qjqTL",
        "colab_type": "code",
        "outputId": "b7c12ccd-6cec-48b5-86e3-f080c63f4345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!tar -xvzf drive/My\\ Drive/talks/Interpretable_NLP/Attention/artifacts.tar.gz -C ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "artifacts/\n",
            "artifacts/graph/\n",
            "artifacts/graph/model.10-0.905-0.255-0.899.hdf5\n",
            "artifacts/pickles/\n",
            "artifacts/pickles/vocab_top_100000_90_percent_model.txt\n",
            "artifacts/pickles/embedding_matrix_100001.npy\n",
            "artifacts/README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHPuobQgjav5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import html\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def html_escape(text):\n",
        "    return html.escape(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFJxV1z4oMp5",
        "colab_type": "text"
      },
      "source": [
        "#### Loading all the artifacts - Pretrained model, Vocab and embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GWzR6gViS3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_weights = \"artifacts/graph/model.10-0.905-0.255-0.899.hdf5\"\n",
        "vocab_file =  \"artifacts/pickles/vocab_top_100000_90_percent_model.txt\"\n",
        "embedding_matrix =  np.load(\"artifacts/pickles/embedding_matrix_100001.npy\")\n",
        "min_percentile = 70\n",
        "vocab = pd.read_fwf(vocab_file, names=[\"words\"],widths=[200]) #widths is important otherwise strings are truncated.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oX8cXJQiS_w",
        "colab_type": "code",
        "outputId": "d254362b-c346-4a27-cbd1-219957a40fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model = model_with_attention_weights(embedding_matrix)\n",
        "model.load_weights(model_weights)\n",
        "graph = tf.get_default_graph()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1113 17:01:04.132328 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1113 17:01:04.142267 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1113 17:01:04.152224 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1113 17:01:04.165747 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W1113 17:01:04.166631 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1113 17:01:04.167714 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1113 17:01:12.177229 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W1113 17:01:12.179330 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "W1113 17:01:12.237494 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "W1113 17:01:15.459451 140653462620032 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W1113 17:01:15.473148 140653462620032 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfITfk7yoees",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the attention weights \n",
        "\n",
        "We select only the top 'n' percentile of weights that are returned from the attention layer. Value 'n' can be controlled with the slider. \n",
        "\n",
        "The words highlighted in the example are the ones that are given importance for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC4KQFIcnCPe",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "7e9ee483-d458-4908-99d3-59cb0fbc43bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#@title Attention visualization\n",
        "\n",
        "labels = [\"negative\",\"neutral\",\"positive\"]\n",
        "\n",
        "def _prepare_text(texts):\n",
        "        processed_texts = []\n",
        "        clean_texts = []\n",
        "        temp_vocab = {}\n",
        "        for text in texts:\n",
        "                text = text.strip()\n",
        "                cleaned_text,text_ids,_ = clean_text(text,vocab,temp_vocab)\n",
        "                processed_texts.append(text_ids)\n",
        "                clean_texts.append(cleaned_text)\n",
        "        return processed_texts,clean_texts\n",
        "\n",
        "   \n",
        "text = \"I love this place. The portions are generous and the plates are fairly priced ($7 to $10 for a plate that includes rice, meats, hummus, and taboule). The workers are always courteous.\" #@param {type:\"string\"}\n",
        "texts,clean_texts = _prepare_text([text])\n",
        "preds,attn_scores = model.predict(np.array(texts))\n",
        "\n",
        "max_alpha = 0.8 \n",
        "min_percentile = 60 #@param {type:\"slider\", min:0, max:100, step:10}\n",
        "highlighted_text = []\n",
        "\n",
        "tokens = text.split()\n",
        "weights = np.squeeze(attn_scores[0])[:len(tokens)]\n",
        "weights = (weights > np.percentile(weights,min_percentile)).astype(int)\n",
        "# max_alpha = np.percentile(weights,min_percentile)\n",
        "\n",
        "  \n",
        "for word,weight in zip(clean_texts[0].split(),weights):\n",
        "    if weight is not None:\n",
        "        highlighted_text.append('<span style=\"background-color:rgba(135,206,250,' + str(weight / max_alpha) + ');\">' + html_escape(str(word)) + '</span>')\n",
        "    else:\n",
        "        highlighted_text.append(str(word))\n",
        "highlighted_text = ' '.join(highlighted_text)\n",
        "\n",
        "\n",
        "print(\"Prediction : {}\".format(labels[np.argmax(preds[0])])+\"\\n\\n\")\n",
        "\n",
        "display(HTML(highlighted_text))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction : positive\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:rgba(135,206,250,1.25);\">love</span> <span style=\"background-color:rgba(135,206,250,1.25);\">place</span> <span style=\"background-color:rgba(135,206,250,1.25);\">.</span> <span style=\"background-color:rgba(135,206,250,1.25);\">portions</span> <span style=\"background-color:rgba(135,206,250,1.25);\">generous</span> <span style=\"background-color:rgba(135,206,250,1.25);\">plates</span> <span style=\"background-color:rgba(135,206,250,1.25);\">fairly</span> <span style=\"background-color:rgba(135,206,250,1.25);\">priced</span> <span style=\"background-color:rgba(135,206,250,1.25);\">(</span> <span style=\"background-color:rgba(135,206,250,1.25);\">$</span> <span style=\"background-color:rgba(135,206,250,0.0);\">7</span> <span style=\"background-color:rgba(135,206,250,0.0);\">$</span> <span style=\"background-color:rgba(135,206,250,0.0);\">10</span> <span style=\"background-color:rgba(135,206,250,0.0);\">plate</span> <span style=\"background-color:rgba(135,206,250,0.0);\">includes</span> <span style=\"background-color:rgba(135,206,250,0.0);\">rice</span> <span style=\"background-color:rgba(135,206,250,0.0);\">,</span> <span style=\"background-color:rgba(135,206,250,0.0);\">meats</span> <span style=\"background-color:rgba(135,206,250,0.0);\">,</span> <span style=\"background-color:rgba(135,206,250,0.0);\">hummus</span> <span style=\"background-color:rgba(135,206,250,0.0);\">,</span> <span style=\"background-color:rgba(135,206,250,0.0);\">taboule</span> <span style=\"background-color:rgba(135,206,250,0.0);\">)</span> <span style=\"background-color:rgba(135,206,250,0.0);\">.</span> <span style=\"background-color:rgba(135,206,250,1.25);\">workers</span> <span style=\"background-color:rgba(135,206,250,0.0);\">always</span> <span style=\"background-color:rgba(135,206,250,1.25);\">courteous</span> <span style=\"background-color:rgba(135,206,250,1.25);\">.</span>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BafKpSjCYY1",
        "colab_type": "text"
      },
      "source": [
        "# Sequence level importance visualization with Segmentation Attention\n",
        "\n",
        "We use a model ([Bailin et el. 2019 ](http://www.statnlp.org/wp-content/uploads/papers/2018/Learning-Latent/absa.pdf)) with the architecture as shown below and train it on a target sentiment analysis task. The segmentation attention provided by CRF helps in extracting opinions that was used by the model in predicting sentiment of the given target word.\n",
        "\n",
        "1. This method is shown to be capable of extracting opinions from sentences that carry multiple targets.\n",
        "\n",
        "2. Authors have used a layer that is analogous to conditional random\n",
        "field (CRF) in the\n",
        "attention modeling process to capture the structural dependencies.The resulting new attention mechanism will be able\n",
        "to perform soft selections of opinion expressions in the form\n",
        "of word spans. This can be viewed as an extension of the\n",
        "standard attention mechanism.Authors call this attention mechanism as segmentation attention\n",
        "\n",
        "-\n",
        "-\n",
        "\n",
        "### **Task** : Target Based sentiment Analysis\n",
        "\n",
        "<img src=\"https://i.imgur.com/pHCkAbd.png\">\n",
        "\n",
        "### **Model Architecture**\n",
        "\n",
        "![Model](https://i.imgur.com/C05Y7Au.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNryzeEECiDk",
        "colab_type": "code",
        "outputId": "f3ce4cc8-240a-469c-cace-e2db460ba35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#!rm -R SA-Sent\n",
        "!git clone https://github.com/infinitylogesh/SA-Sent.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SA-Sent'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "Unpacking objects:   4% (1/25)   \rUnpacking objects:   8% (2/25)   \rUnpacking objects:  12% (3/25)   \rUnpacking objects:  16% (4/25)   \rUnpacking objects:  20% (5/25)   \rUnpacking objects:  24% (6/25)   \rUnpacking objects:  28% (7/25)   \rUnpacking objects:  32% (8/25)   \rUnpacking objects:  36% (9/25)   \rUnpacking objects:  40% (10/25)   \rUnpacking objects:  44% (11/25)   \rremote: Total 25 (delta 0), reused 0 (delta 0), pack-reused 25\u001b[K\n",
            "Unpacking objects:  48% (12/25)   \rUnpacking objects:  52% (13/25)   \rUnpacking objects:  56% (14/25)   \rUnpacking objects:  60% (15/25)   \rUnpacking objects:  64% (16/25)   \rUnpacking objects:  68% (17/25)   \rUnpacking objects:  72% (18/25)   \rUnpacking objects:  76% (19/25)   \rUnpacking objects:  80% (20/25)   \rUnpacking objects:  84% (21/25)   \rUnpacking objects:  88% (22/25)   \rUnpacking objects:  92% (23/25)   \rUnpacking objects:  96% (24/25)   \rUnpacking objects: 100% (25/25)   \rUnpacking objects: 100% (25/25), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_a-enTZIcjl",
        "colab_type": "code",
        "outputId": "800947fc-0685-4c74-bda4-23eb221edd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls drive/My\\ Drive/talks/Interpretable_NLP/Attention_CRF/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.pkl  dic.pkl  pre-trained-glove.pkl  target_model_best.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQPS8YSTFijj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_crf_path = \"drive/My Drive/talks/Interpretable_NLP/Attention_CRF\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy5N0VKyHzNk",
        "colab_type": "code",
        "outputId": "a7a8820d-f412-4d0e-9ea3-559c88f0cce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "\n",
        "sys.path.insert(0, './SA-Sent')\n",
        "model = torch.load(attention_crf_path+\"/target_model_best.pt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'model.AspectSent' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvv2aDhFApIx",
        "colab_type": "code",
        "outputId": "9a59d616-7b9e-4921-c29d-5bb7852a43e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AspectSent(\n",
              "  (cat_layer): SimpleCat(\n",
              "    (word_embed): Embedding(5135, 300)\n",
              "    (mask_embed): Embedding(2, 50)\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (lstm): MLSTM(\n",
              "    (rnn): LSTM(350, 100, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  )\n",
              "  (feat2tri): Linear(in_features=200, out_features=2, bias=True)\n",
              "  (inter_crf): LinearCRF()\n",
              "  (feat2label): Linear(in_features=200, out_features=3, bias=True)\n",
              "  (cri): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLVTidH8JznU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en\")\n",
        "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
        "\n",
        "\n",
        "dic = cPickle.load(open(attention_crf_path+\"/dic.pkl\",\"r\"))\n",
        "id2vec = cPickle.load(open(attention_crf_path+\"/pre-trained-glove.pkl\",\"r\"))\n",
        "data = cPickle.load(open(attention_crf_path+\"/data.pkl\",\"r\"))\n",
        " \n",
        "\n",
        "id2word = list(dic)\n",
        "word2id = {v:k for k,v in enumerate(id2word)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAl73bCeNRgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  text = \" \".join(text.split(\"-\"))\n",
        "  text = \" \".join(text.split(\"/\"))\n",
        "  text = \" \".join(text.split(\"!\"))\n",
        "  return list(nlp(unicode(text)))\n",
        "\n",
        "def vectorizer(text):\n",
        "  sent_ids = [word2id[str(token)] if str(token) in word2id else word2id[\"UNK\"] for token in tokenize(text)]\n",
        "  return sent_ids\n",
        "\n",
        "def prepare_mask(review,target):\n",
        "  mask = [0]*len(list(tokenize(review)))\n",
        "  for target_token in  target.split(\" \"):\n",
        "    for i,token in enumerate(tokenize(review)):\n",
        "      if str(token) == target_token :\n",
        "        mask[i] = 1\n",
        "  return mask\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrlvICI9lvM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import html\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "def html_escape(text):\n",
        "    return html.escape(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p6K22rhR2_t",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "a9ffbec8-1191-4b78-90ca-317185f7d4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#@title Attention with CRF\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
        "\n",
        "review = \"the food is usually good certainly isn't a relaxing place to go\" #@param [\"the food was bad but the waiter was very nice\",\"the food is usually good but certainly isn't a relaxing place to go\",\"the food is usually good certainly isn't a relaxing place to go\",\"Great beer selection too with 50 beers in the list\"] {type:\"string\"}\n",
        "target = \"place\" #@param {type:\"string\"}\n",
        "mask = prepare_mask(review,target)\n",
        "sent_ids = vectorizer(review)\n",
        "\n",
        "labels = [\"positive\", \"neutral\", \"negative\"]\n",
        "assert len(list(tokenize(review))) == len(mask)\n",
        "\n",
        "model.eval()\n",
        "prediction , activated_sequences =  model.predict(sent_ids,mask)\n",
        "\n",
        "max_alpha = 0.8 \n",
        "highlighted_text = []\n",
        "for word,weight in zip(tokenize(review),activated_sequences):\n",
        "   \n",
        "    if weight is not None:\n",
        "        highlighted_text.append('<span style=\"background-color:rgba(135,206,250,' + str(weight / max_alpha) + ');\">' + html_escape(str(word)) + '</span>')\n",
        "    else:\n",
        "        highlighted_text.append(str(word))\n",
        "highlighted_text = ' '.join(highlighted_text)\n",
        "\n",
        "\n",
        "print(\"Predcition: {} \\n\".format(labels[prediction]))\n",
        "\n",
        "display(HTML(highlighted_text))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predcition: positive \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span style=\"background-color:rgba(135,206,250,1.25);\">the</span> <span style=\"background-color:rgba(135,206,250,1.25);\">food</span> <span style=\"background-color:rgba(135,206,250,1.25);\">is</span> <span style=\"background-color:rgba(135,206,250,1.25);\">usually</span> <span style=\"background-color:rgba(135,206,250,1.25);\">good</span> <span style=\"background-color:rgba(135,206,250,1.25);\">certainly</span> <span style=\"background-color:rgba(135,206,250,1.25);\">is</span> <span style=\"background-color:rgba(135,206,250,1.25);\">n&#x27;t</span> <span style=\"background-color:rgba(135,206,250,1.25);\">a</span> <span style=\"background-color:rgba(135,206,250,1.25);\">relaxing</span> <span style=\"background-color:rgba(135,206,250,1.25);\">place</span> <span style=\"background-color:rgba(135,206,250,1.25);\">to</span> <span style=\"background-color:rgba(135,206,250,1.25);\">go</span>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MY23_Cf1_8g",
        "colab_type": "code",
        "outputId": "7422ab50-bac9-431c-c22f-cd50e4a73a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the food was bad but the waiter was very nice\n",
        "# the food is usually good but certainly isn't a relaxing place to go \n",
        "# Intimate but charming interior with extremely friendly and attentive service . - Service\n",
        "# Great beer selection too with 50 beers in the list - beer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}