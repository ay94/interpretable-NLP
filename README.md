# Interpretable NLP Talk
Contents of Hack Session on Interpreting NLP models at DataHack Summit 2019.

## Files :

 - Dathack_2019_LSTM_Attention.ipynb : Notebook explaining attention visualisation for LSTM based models [[colab link](https://colab.research.google.com/drive/1MACM9c3tnHRBKvV485LNO0lWBvlwbEed)]
 -  Dathack_2019_LSTM_Attention.ipynb : Notebook explaing basic language and positional features learned by Transformers [[colab link](https://colab.research.google.com/drive/1z5W-JGtYBFfbIWZbIO73z0oIWtEFZJYO)]
 -  Datahack_2019_transformers_task_features.ipynb : Notebook to interpret task spefic feature learnings of Transformers [[colab link](https://colab.research.google.com/drive/1P4HWHso-bV5vW8pKDSqPERet507KGlr3)]
 

 **Please feel free to create an issue for question or requests.**
